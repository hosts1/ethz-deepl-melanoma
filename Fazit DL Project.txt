

Fazit: 

Allgemein: 
CNN performen schlechter als RF -> zu viele Parameter welche getunt werden können? 
Fitten die jetztigen NN die lokalen Minima?  (learning rate zu gross)
choose correct hyperparamter (learning rate) https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/
	 " Smaller learning rates require more training epochs given the smaller changes made to the weights each update" -> hätten wir mehr epochs nehmen sollen als die 20 fürs VGG based training und die 30 fürs from scratch trained CNN 
epochs = the number of complete passes through the training dataset
	https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/
Zu viele/wenige Neuronen? Optimierung mit mehr hiden layers? 

Maybe use a different optimizer than "adam" to compile the model?  https://keras.io/api/optimizers/
"adam" is an optimized algorithm instead of classical  SGD as stocahstic gradient descent, that can work with non-convex optimization problems (thus local minima instead of global minima?)


Hauptproblem: 
Schlechte Bildqualität 
	- verschiedene Auflösungen 
	- verschiedene Farbtiefe
	- tw. Markierungen (violett) vorhanden was fälschlicherweise auch für die Definition von Klassifizerung Parameter füren kann


Imbalanced data: 
	- es sind nicht gleich viele Bilder von Nevus, seborheic keratoris, Melanoma vorhanden was für CNN ein grössere Problem als für RF darstellt
	- Bei RF kann imbalanced data mit weighted random forest, balanced random forest ausgebessert werden
	- Bei Tensorflow werden die techniken von class weighting/ oversampling verwendet 	(https://www.tensorflow.org/tutorials/structured_data/imbalanced_data)


Overfitting bei CNN from scratch: 

data augmentation (Erzeugung von mehr und unterschiedl. Daten Generierung durch drehen, zuschneiden, etc. der Ursprungsdaten(: 
hat nicht funktioniert bei uns, weil auch nach einem Keras updat von 2.6 auf 2.9 die Fehlermeldung: "could not find function "layer_random_flip" kam. 


dropout layes: 
https://github.com/dropreg/R-Drop -> wurde mit der layer_dropout umgesetzt


RF vs. CNN: https://towardsdatascience.com/3-reasons-to-use-random-forest-over-a-neural-network-comparing-machine-learning-versus-deep-f9d65a154d89		

why lower accuracy of the CNN than RF

pretrained CNN with VGG: maybe to many features 
CNN from scratch: not enough data to define features


Why CNN from scratch could not perform as good even when using dropout layers: 
- amount of data (to few and imbalanced per category)
- regularization/ maybe to few validation data? 
 